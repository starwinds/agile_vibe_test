# ğŸ§­ Gemini CLI Prompt: Valkey + Valkey VectorSearch Python App Setup

## ğŸ¯ ëª©ì 
ì´ í”„ë¡œì íŠ¸ëŠ” **Valkey(ì˜¤í”ˆì†ŒìŠ¤ Redis í¬í¬)** ì˜ **VectorSearch ê¸°ëŠ¥**ì„ í™œìš©í•˜ì—¬  
Python ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ë¬¸ì¥ ì„ë² ë”© ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³ ,  
ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ì˜ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ìƒ˜í”Œ ì•±ì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ Agile + TDD í™˜ê²½ì„ ìë™ êµ¬ì„±í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

---

## âš™ï¸ 1ï¸âƒ£ Valkey (VectorSearch, Docker)

```bash
docker run -d \
  --name valkey-vector \
  -p 6379:6379 \
  valkey/valkey:latest \
  --loadmodule /usr/lib/valkey/modules/vectorsearch.so
```

---

## ğŸ§° 2ï¸âƒ£ Python í™˜ê²½ ë° requirements.txt

```
redis==5.0.1
sentence-transformers==3.0.1
numpy>=1.26.0
pytest==8.3.2
pytest-cov==5.0.0
flask>=3.0.0
```

---

## ğŸ§© 3ï¸âƒ£ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ğŸ“¦ valkey-vector-app/
 â”£ ğŸ“‚ src/
 â”ƒ â”£ app.py
 â”ƒ â”£ db_utils.py
 â”ƒ â”— embedding.py
 â”£ ğŸ“‚ tests/
 â”ƒ â”£ test_embedding.py
 â”ƒ â”— test_db.py
 â”£ ğŸ“‚ docs/
 â”ƒ â”£ prd.md
 â”ƒ â”£ backlog.md
 â”ƒ â”£ sprint_plan.md
 â”ƒ â”£ sprint2_plan.md
 â”ƒ â”£ progress.md
 â”ƒ â”— retro.md
 â”£ requirements.txt
 â”£ pytest.ini
 â”— README.md
```

---

## ğŸ§  4ï¸âƒ£ ì½”ë“œ ìŠ¤ì¼ˆë ˆí†¤

### src/embedding.py
```python
from sentence_transformers import SentenceTransformer
import numpy as np

model = SentenceTransformer("all-MiniLM-L6-v2")  # 384ì°¨ì› ëª¨ë¸

def get_embedding(text: str) -> bytes:
    embedding = model.encode(text)
    return np.array(embedding, dtype=np.float32).tobytes()
```

### src/app.py
```python
from flask import Flask, request, jsonify, render_template_string
from .embedding import get_embedding
from .db_utils import connect, search_similar, insert_doc, create_index
import numpy as np
import uuid

app = Flask(__name__)

@app.route('/')
def hello_world():
    html_content = """
<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>QA Service</title>
    <style>
        body { font-family: sans-serif; margin: 2em; }
        h1, h2 { color: #333; }
        form { margin-bottom: 2em; }
        label { display: block; margin-bottom: 0.5em; }
        input[type="text"], textarea { width: 100%; padding: 0.5em; margin-bottom: 1em; }
        #answer { background-color: #f0f0f0; padding: 1em; border-radius: 5px; }
    </style>
</head>
<body>
    <h1>QA Service</h1>

    <h2>Ask a Question</h2>
    <form action="/qa" method="get" id="qa-form">
        <label>Question:</label>
        <input type="text" name="question">
        <button type="submit">Ask</button>
    </form>
    <div id="answer"></div>

    <h2>Add a Document</h2>
    <form action="/add_document" method="post" id="add-doc-form">
        <label>Document Content:</label>
        <textarea name="document" rows="5"></textarea>
        <button type="submit">Add Document</button>
    </form>
    <div id="add-doc-status"></div>
    <script>
        document.getElementById('qa-form').addEventListener('submit', async function(event) {
            event.preventDefault();
            const question = document.querySelector('#qa-form input[name="question"]').value;
            const responseDiv = document.getElementById('answer');
            responseDiv.innerHTML = 'Loading...';

            try {
                const response = await fetch(`/qa?question=${encodeURIComponent(question)}`);
                const data = await response.json();
                if (response.ok) {
                    responseDiv.innerHTML = `<strong>Answer:</strong> ${data.answer}`;
                } else {
                    responseDiv.innerHTML = `<strong>Error:</strong> ${data.error || 'Unknown error'}`;
                }
            } catch (error) {
                responseDiv.innerHTML = `<strong>Error:</strong> ${error.message}`;
            }
        });

        document.getElementById('add-doc-form').addEventListener('submit', async function(event) {
            event.preventDefault();
            const documentContent = document.querySelector('#add-doc-form textarea[name="document"]').value;
            const statusDiv = document.getElementById('add-doc-status');
            statusDiv.innerHTML = 'Adding document...';

            try {
                const response = await fetch('/add_document', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ document: documentContent })
                });
                const data = await response.json();
                if (response.ok) {
                    statusDiv.innerHTML = `<strong>Success:</strong> ${data.message} (ID: ${data.doc_id})`;
                    document.querySelector('#add-doc-form textarea[name="document"]').value = ''; // Clear textarea
                } else {
                    statusDiv.innerHTML = `<strong>Error:</strong> ${data.error || 'Unknown error'}`;
                }
            } catch (error) {
                statusDiv.innerHTML = `<strong>Error:</strong> ${error.message}`;
            }
        });
    </script>
</body>
</html>
"""
    return render_template_string(html_content)

@app.route('/qa', methods=['GET'])
def qa():
    question = request.args.get('question')
    if not question:
        return jsonify({"error": "Question parameter is required"}), 400

    query_embedding = get_embedding(question)
    # The vector from get_embedding is bytes, but search_similar expects a list/numpy array of floats.
    # Let's convert it back.
    query_vector = np.frombuffer(query_embedding, dtype=np.float32)

    conn = connect()
    results = search_similar(conn, query_vector, limit=1)

    if not results:
        return jsonify({"answer": "No similar documents found."})

    return jsonify({"answer": results[0]['content']})

@app.route('/add_document', methods=['POST'])
def add_document():
    data = request.get_json()
    document_content = data.get('document')

    if not document_content:
        return jsonify({"error": "Document content is required"}), 400

    doc_id = str(uuid.uuid4())
    embedding = get_embedding(document_content)

    conn = connect()
    insert_doc(conn, doc_id, document_content, embedding)

    return jsonify({"message": "Document added successfully", "doc_id": doc_id}), 201


if __name__ == '__main__':
    conn = connect()
    create_index(conn)
    app.run(debug=True)
```

### src/db_utils.py
```python
import redis
import numpy as np
from redis.commands.search.field import TagField, VectorField
from redis.commands.search.query import Query

def connect():
    return redis.Redis(host="127.0.0.1", port=6379, db=0, decode_responses=False)

def create_index(conn):
    try:
        conn.ft("doc_index").info()
    except redis.exceptions.ResponseError:
        # Index does not exist, create it
        conn.ft("doc_index").create_index([
            TagField("content"),
            VectorField(
                "embedding",
                "HNSW",
                {"TYPE": "FLOAT32", "DIM": 384, "DISTANCE_METRIC": "COSINE"}
            )
        ])

def insert_doc(conn, doc_id, content, embedding):
    conn.hset(f"doc:{doc_id}", mapping={
        "content": content,
        "embedding": embedding
    })

def search_similar(conn, query_vec, limit=3):
    vec_bytes = np.array(query_vec, dtype=np.float32).tobytes()
    search_query = Query(f"*=>[KNN {limit} @embedding $vec AS score]")
    result = conn.ft("doc_index").search(
        search_query,
        query_params={"vec": vec_bytes}
    )
    docs = []
    for d in result.docs:
        docs.append({"id": d.id, "content": d.content, "score": float(d.score)})
    return docs
```

---


## ğŸ§ª 5ï¸âƒ£ TDDD ë°©ì‹ ê°œë°œ ê°€ì´ë“œ

### ê°œë°œ ê°€ì´ë“œ ë¬¸ì„œ
- ì•„ë˜ ê²½ë¡œì˜ ê°€ì´ë“œ ë¬¸ì„œ ì°¸ì¡°

/home/ubuntu/dev-proj/valkey_agile_test/docs/dev_guide.txt


## ğŸ§ª ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ ì½”ë“œ

### tests/test_embedding.py
```python
from src.embedding import get_embedding
import numpy as np

def test_embedding_shape():
    vec = get_embedding("Hello")
    assert isinstance(vec, bytes)
    assert len(np.frombuffer(vec, dtype=np.float32)) == 384
```

### tests/test_db.py
```python
from src.db_utils import connect, create_index, insert_doc, search_similar
from src.embedding import get_embedding
import numpy as np

def test_db_insert_and_search():
    conn = connect()
    create_index(conn)

    emb = get_embedding("AI development")
    insert_doc(conn, "1", "AI development", emb)

    q = np.frombuffer(get_embedding("artificial intelligence"), dtype=np.float32)
    results = search_similar(conn, q, limit=1)
    assert len(results) >= 1
```

---

## ğŸ“„ Agile ë¬¸ì„œ ì„¸íŠ¸

### docs/prd.md
- í”„ë¡œì íŠ¸ ê°œìš”, ëª©í‘œ, ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤, ê¸°ëŠ¥ ì •ì˜
- â€œPostgreSQL + pgvector í™•ì¥ì„ í™œìš©í•˜ì—¬ ë¬¸ì¥ ì„ë² ë”© ì €ì¥ ë° ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„â€ ëª…ì‹œ

### docs/backlog.md
- Epic/Story/Task ê¸°ë°˜ ì •ì˜
- ì£¼ìš” í•­ëª©: DB ì„¤ì¹˜, Embedding ìƒì„±, ê²€ìƒ‰, í…ŒìŠ¤íŠ¸ ìë™í™”

### docs/sprint_plan.md
- Sprint 1 ê¸°ê°„, ëª©í‘œ, Capacity, Definition of Done í¬í•¨

### docs/progress.md
- ë‚ ì§œ / ì‘ì—… / í…ŒìŠ¤íŠ¸ ê²°ê³¼ / ì»¤ë²„ë¦¬ì§€ ì •ë¦¬

### docs/retro.md
- ì˜ëœ ì  / ê°œì„ ì  / ë‹¤ìŒ ìŠ¤í”„ë¦°íŠ¸ ì•¡ì…˜ ì•„ì´í…œ

---

## ğŸš€ ì‹¤í–‰

```bash
docker ps
source .venv/bin/activate
python3 -m src.app # Flask ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰
# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ Valkey ì¸ë±ìŠ¤ê°€ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.
pytest --cov=src -v
```

---

## ğŸ“„ ì‚¬ìš©ì ê°€ì´ë“œ ì—…ë°ì´íŠ¸

ìì„¸í•œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‚¬ìš© ë°©ë²•ì€ ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤:
- valkey_agile_test/valkey-vector-app/docs/user_guide.md

---

## ğŸ“¦ Gemini CLI ì‹¤í–‰
```bash
gemini prompt -f setup_valkey_vector_app.md
```
